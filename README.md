# ğŸ“ˆ Reinforcement Learning for Portfolio Management

A professional research-driven system that applies **Deep Reinforcement Learning (DRL)** to optimize multi-asset portfolios.  
The platform supports **PPO**, **TD3**, and **SAC** agents, multiple strategy modes, goal-based investing, and live market data simulation.  
Developed as part of my **Summer Research Internship**, this project bridges academic research and real-world financial trading systems.

---

## ğŸš€ Key Features

- **Multiple DRL Agents**
  - PPO, TD3, SAC implemented using a unified `BaseAgent` interface.
- **Custom Portfolio Environment**
  - Long-only, long-short, and hedged strategies.
  - Reward shaping to balance profitability, volatility, and drawdown.
  - Log-return based state representation for numerical stability.
- **Goal-Based Investing**
  - Set profit target, duration, and risk level.
  - Automatic strategy replanning when goals are unachievable.
- **Data Integration**
  - Historical market data for training.
  - Real-time-like data streaming via `yfinance` (modular for easy broker API integration like Zerodha Kite or Alpaca).
- **Advanced Evaluation**
  - Sharpe ratio, volatility, max drawdown, and annualized returns.
  - Visualizations: portfolio weight heatmaps, trade frequency analysis, and equity curves.
- **Interactive Dashboard**
  - Streamlit-based interface for strategy simulation.
  - Compare agent strategies against baseline benchmarks.

---

## ğŸ“‚ Project Structure

.
â”œâ”€â”€ agents/ # PPO, TD3, SAC agent implementations
â”œâ”€â”€ env/ # Custom OpenAI Gym-like portfolio environment
â”œâ”€â”€ train/ # Standalone training scripts
â”œâ”€â”€ utils/ # Data handling, metrics, plotting, broker APIs, etc.
â”œâ”€â”€ scripts/ # Testing and visualization utilities
â”œâ”€â”€ logs/ # Training and evaluation logs
â”œâ”€â”€ main.py # CLI entry point for training and evaluation
â”œâ”€â”€ evaluate.py # Evaluate trained agents
â”œâ”€â”€ optuna_tune.py # Hyperparameter tuning via Optuna
â”œâ”€â”€ streamlit_app.py # Streamlit dashboard for strategy simulation
â””â”€â”€ requirements.txt # Python dependencies
---

## âš™ï¸ Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/rl-portfolio-management.git
cd rl-portfolio-management

# Create and activate a virtual environment (recommended)
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

```
---

## ğŸ“Š Training Agents
```bash
#Train a PPO agent:
python train/train_ppo.py

#Train a TD3 agent:
python train/train_td3.py

#Train a SAC agent:
python train/train_sac.py
```
---

##ğŸ–¥ Interactive Dashboard
```bash
#Launch the Streamlit dashboard:
streamlit run streamlit_app.py
```
---
##ğŸ“ˆ Evaluation
```bas
#Evaluate a trained agent on test data:
python evaluate.py --agent PPO --model_path ppo_portfolio.zip
```
---
##ğŸ“œ Research Context

-**This system was developed to:**
  - Explore DRLâ€™s ability to adapt to dynamic market conditions.
  - Integrate financial risk measures directly into the reward function.
  - Build a modular, production-ready RL trading system with real-time capabilities.
  - It combines quantitative finance techniques with deep reinforcement learning algorithms to move beyond static optimization and towards adaptive decision-making.
  
  ---
##ğŸ›  Tech Stack

-Python 3.9+
-Stable-Baselines3
-Pandas / NumPy
-Matplotlib
-Optuna
-Streamlit
-yfinance
---

##ğŸ“š References

-Jiang, M., Xu, D., Liang, Y., â€œDeep Reinforcement Learning for Trading,â€ 2017.
-OpenAI Spinning Up Documentation.
-Stable-Baselines3 Documentation.
---
